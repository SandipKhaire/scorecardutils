{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_credit_risk_data(n_samples=50000, default_rate=0.10):\n",
    "    \"\"\"\n",
    "    Generate synthetic credit risk data with specified characteristics.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: Number of data points to generate\n",
    "    - default_rate: Proportion of default cases (target=1)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with features and target variable\n",
    "    \"\"\"\n",
    "    # Calculate number of defaults\n",
    "    n_defaults = int(n_samples * default_rate)\n",
    "    n_non_defaults = n_samples - n_defaults\n",
    "    \n",
    "    # Generate base data with 10 informative features\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=10,  # We'll expand to 50 later\n",
    "        n_informative=8,  # Truly informative\n",
    "        n_redundant=2,   # Correlated features\n",
    "        n_classes=2,\n",
    "        weights=[1-default_rate, default_rate],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    feature_names = [f\"feature_{i+1}\" for i in range(X.shape[1])]\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    \n",
    "    # Rename the first 10 features to meaningful names\n",
    "    # Highly predictive numeric variables (6)\n",
    "    df.rename(columns={\n",
    "        'feature_1': 'income',\n",
    "        'feature_2': 'debt_to_income_ratio',\n",
    "        'feature_3': 'credit_score',\n",
    "        'feature_4': 'loan_amount', \n",
    "        'feature_5': 'interest_rate',\n",
    "        'feature_6': 'age',\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Create a highly correlated feature with income\n",
    "    df['total_assets'] = df['income'] * np.random.normal(3, 0.2, n_samples) + np.random.normal(0, 0.5, n_samples)\n",
    "    \n",
    "    # Transform features to more realistic ranges\n",
    "    df['income'] = (df['income'] * 20000 + 50000).clip(10000, 250000)\n",
    "    df['debt_to_income_ratio'] = (df['debt_to_income_ratio'] + 3) / 6  # Scale to 0-1 range\n",
    "    df['debt_to_income_ratio'] = (df['debt_to_income_ratio'] * 0.6 + 0.1).clip(0.05, 0.8)  \n",
    "    df['credit_score'] = (df['credit_score'] * 150 + 650).clip(300, 850).astype(int)\n",
    "    df['loan_amount'] = (df['loan_amount'] * 50000 + 100000).clip(5000, 500000)\n",
    "    df['interest_rate'] = (df['interest_rate'] + 3) / 6 * 15 + 2  # Interest rate between 2% and 17%\n",
    "    df['age'] = (df['age'] * 20 + 40).clip(18, 85).astype(int)\n",
    "    \n",
    "    # Highly predictive categorical variables (4)\n",
    "    # Feature 7: employment_status (categorical)\n",
    "    employment_statuses = ['Employed', 'Self-Employed', 'Unemployed', 'Retired']\n",
    "    # Make employment more predictive - separate probability arrays for default vs non-default\n",
    "    employed_prob_default = [0.3, 0.2, 0.4, 0.1]\n",
    "    employed_prob_nondefault = [0.7, 0.2, 0.05, 0.05]\n",
    "    \n",
    "    # Create array to store employment status\n",
    "    employment_status = []\n",
    "    for i in range(n_samples):\n",
    "        if y[i] == 1:\n",
    "            employment_status.append(np.random.choice(employment_statuses, p=employed_prob_default))\n",
    "        else:\n",
    "            employment_status.append(np.random.choice(employment_statuses, p=employed_prob_nondefault))\n",
    "    \n",
    "    df['employment_status'] = employment_status\n",
    "    \n",
    "    # Feature 8: education_level (categorical)\n",
    "    education_levels = ['High School', 'Bachelor', 'Master', 'PhD', 'Other']\n",
    "    # Make education more predictive - separate probability arrays\n",
    "    education_prob_default = [0.5, 0.3, 0.1, 0.05, 0.05]\n",
    "    education_prob_nondefault = [0.2, 0.4, 0.3, 0.08, 0.02]\n",
    "    \n",
    "    # Create array to store education level\n",
    "    education_level = []\n",
    "    for i in range(n_samples):\n",
    "        if y[i] == 1:\n",
    "            education_level.append(np.random.choice(education_levels, p=education_prob_default))\n",
    "        else:\n",
    "            education_level.append(np.random.choice(education_levels, p=education_prob_nondefault))\n",
    "    \n",
    "    df['education_level'] = education_level\n",
    "    \n",
    "    # Feature 9: loan_purpose (categorical)\n",
    "    loan_purposes = ['Home', 'Auto', 'Education', 'Personal', 'Business', 'Debt Consolidation']\n",
    "    # Make loan_purpose more predictive\n",
    "    purpose_prob_default = [0.1, 0.15, 0.2, 0.2, 0.25, 0.1]\n",
    "    purpose_prob_nondefault = [0.3, 0.2, 0.1, 0.1, 0.1, 0.2]\n",
    "    \n",
    "    # Create array to store loan purpose\n",
    "    loan_purpose = []\n",
    "    for i in range(n_samples):\n",
    "        if y[i] == 1:\n",
    "            loan_purpose.append(np.random.choice(loan_purposes, p=purpose_prob_default))\n",
    "        else:\n",
    "            loan_purpose.append(np.random.choice(loan_purposes, p=purpose_prob_nondefault))\n",
    "    \n",
    "    df['loan_purpose'] = loan_purpose\n",
    "    \n",
    "    # Feature 10: has_previous_defaults (categorical but binary)\n",
    "    # Make previous defaults highly predictive\n",
    "    has_previous_defaults = []\n",
    "    for i in range(n_samples):\n",
    "        if y[i] == 1:\n",
    "            # 70% of defaulters have previous defaults\n",
    "            has_previous_defaults.append(np.random.choice([1, 0], p=[0.7, 0.3]))\n",
    "        else:\n",
    "            # 10% of non-defaulters have previous defaults\n",
    "            has_previous_defaults.append(np.random.choice([1, 0], p=[0.1, 0.9]))\n",
    "    \n",
    "    df['has_previous_defaults'] = [('Yes' if val == 1 else 'No') for val in has_previous_defaults]\n",
    "    \n",
    "    # Create a correlated categorical variable with employment_status\n",
    "    # payment_history (correlated with employment_status)\n",
    "    payment_history_map = {\n",
    "        'Employed': np.array(['Excellent', 'Good', 'Fair', 'Poor']),\n",
    "        'Self-Employed': np.array(['Good', 'Fair', 'Fair', 'Poor']),\n",
    "        'Unemployed': np.array(['Fair', 'Poor', 'Poor', 'Poor']), \n",
    "        'Retired': np.array(['Excellent', 'Good', 'Fair', 'Poor'])\n",
    "    }\n",
    "    \n",
    "    # Create probabilities for payment_history based on employment status\n",
    "    payment_probs = {\n",
    "        'Employed': [0.5, 0.3, 0.15, 0.05],\n",
    "        'Self-Employed': [0.3, 0.4, 0.2, 0.1],\n",
    "        'Unemployed': [0.1, 0.2, 0.3, 0.4],\n",
    "        'Retired': [0.4, 0.3, 0.2, 0.1]\n",
    "    }\n",
    "    \n",
    "    payment_history = []\n",
    "    for status in df['employment_status']:\n",
    "        payment_history.append(np.random.choice(payment_history_map[status], p=payment_probs[status]))\n",
    "    \n",
    "    df['payment_history'] = payment_history\n",
    "    \n",
    "    # Add remaining 40 less predictive features (mix of numeric and categorical)\n",
    "    # Numeric features (30)\n",
    "    for i in range(1, 31):\n",
    "        # Generate less predictive numeric features\n",
    "        feature_name = f'numeric_feature_{i}'\n",
    "        if i <= 5:  # First 5 slightly more predictive than the rest\n",
    "            feature_values = np.random.normal(0, 1, n_samples) + y * np.random.uniform(0.1, 0.3)\n",
    "        else:  # Remaining 25 features are mostly noise\n",
    "            feature_values = np.random.normal(0, 1, n_samples) + y * np.random.uniform(0, 0.1)\n",
    "            \n",
    "        # Apply different transformations to make features diverse\n",
    "        if i % 4 == 0:\n",
    "            # Exponential-like features (e.g., transaction amounts)\n",
    "            feature_values = np.exp(feature_values * 0.5) * 100\n",
    "        elif i % 4 == 1:\n",
    "            # Percentage-like features (e.g., utilization rates)\n",
    "            feature_values = stats.norm.cdf(feature_values) * 100\n",
    "        elif i % 4 == 2:\n",
    "            # Count-like features (e.g., number of inquiries)\n",
    "            feature_values = np.abs(feature_values * 5).astype(int)\n",
    "        # else leave as standard normal\n",
    "            \n",
    "        df[feature_name] = feature_values\n",
    "    \n",
    "    # Categorical features (10)\n",
    "    categorical_vars = [\n",
    "        ('marital_status', ['Single', 'Married', 'Divorced', 'Widowed']),\n",
    "        ('housing_status', ['Own', 'Mortgage', 'Rent', 'Other']),\n",
    "        ('job_industry', ['Technology', 'Healthcare', 'Finance', 'Education', 'Manufacturing', 'Retail', 'Other']),\n",
    "        ('state', ['CA', 'NY', 'TX', 'FL', 'IL', 'PA', 'OH', 'GA', 'Other']),\n",
    "        ('credit_card_type', ['Visa', 'Mastercard', 'Amex', 'Discover', 'None']),\n",
    "        ('num_dependents', [0, 1, 2, 3, 4, '5+']),\n",
    "        ('months_at_current_job', ['<6', '6-12', '1-3 years', '3-5 years', '5+ years']),\n",
    "        ('has_cosigner', ['Yes', 'No']),\n",
    "        ('account_type', ['Checking', 'Savings', 'Both', 'None']),\n",
    "        ('application_channel', ['Online', 'In-person', 'Phone', 'Mail'])\n",
    "    ]\n",
    "    \n",
    "    for i, (feature_name, categories) in enumerate(categorical_vars):\n",
    "        # For first 3 categorical variables, make them slightly predictive\n",
    "        if i < 3:\n",
    "            # Different probability distributions based on target\n",
    "            p_default = np.random.dirichlet(np.ones(len(categories)) * 2)\n",
    "            p_non_default = np.random.dirichlet(np.ones(len(categories)) * 2)\n",
    "            \n",
    "            # Ensure some difference between distributions\n",
    "            max_idx = np.argmax(p_default)\n",
    "            p_default[max_idx] += 0.1\n",
    "            p_default = p_default / sum(p_default)\n",
    "            \n",
    "            # Choose categories based on target\n",
    "            cat_values = []\n",
    "            for target_val in y:\n",
    "                if target_val == 1:\n",
    "                    cat_values.append(np.random.choice(categories, p=p_default))\n",
    "                else:\n",
    "                    cat_values.append(np.random.choice(categories, p=p_non_default))\n",
    "        else:\n",
    "            # For the rest, almost no predictive power\n",
    "            cat_values = np.random.choice(categories, size=n_samples)\n",
    "            \n",
    "        df[feature_name] = cat_values\n",
    "    \n",
    "    # Add target variable\n",
    "    df['default'] = y\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the dataset\n",
    "credit_risk_df = generate_credit_risk_data(n_samples=50000, default_rate=0.10)\n",
    "\n",
    "# Verify the default rate\n",
    "default_rate = credit_risk_df['default'].mean()\n",
    "print(f\"Default rate in the dataset: {default_rate:.4f}\")\n",
    "\n",
    "# Check correlation between income and total_assets (should be highly correlated)\n",
    "income_assets_corr = credit_risk_df['income'].corr(credit_risk_df['total_assets'])\n",
    "print(f\"Correlation between income and total_assets: {income_assets_corr:.4f}\")\n",
    "\n",
    "# Check correlation between employment_status and payment_history (categorical correlation)\n",
    "crosstab = pd.crosstab(credit_risk_df['employment_status'], credit_risk_df['payment_history'])\n",
    "print(\"\\nCrosstab of employment_status and payment_history:\")\n",
    "print(crosstab)\n",
    "\n",
    "# Show information about the dataset\n",
    "print(\"\\nDataset information:\")\n",
    "print(f\"Total rows: {len(credit_risk_df)}\")\n",
    "print(f\"Total columns: {len(credit_risk_df.columns)}\")\n",
    "print(f\"Default cases: {credit_risk_df['default'].sum()}\")\n",
    "print(f\"Non-default cases: {len(credit_risk_df) - credit_risk_df['default'].sum()}\")\n",
    "\n",
    "# Show a sample of the data\n",
    "print(\"\\nSample of the generated dataset:\")\n",
    "print(credit_risk_df.head())\n",
    "\n",
    "# Feature importance analysis\n",
    "# We'll use correlation for numeric features and chi-square for categorical\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Analyze numeric features\n",
    "numeric_features = credit_risk_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numeric_features = [col for col in numeric_features if col != 'default']\n",
    "\n",
    "print(\"\\nCorrelation of numeric features with default:\")\n",
    "correlations = {}\n",
    "for col in numeric_features:\n",
    "    corr = credit_risk_df[col].corr(credit_risk_df['default'])\n",
    "    correlations[col] = abs(corr)\n",
    "\n",
    "sorted_numeric = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "for feature, corr in sorted_numeric[:15]:  # Show top 15\n",
    "    print(f\"{feature}: {corr:.4f}\")\n",
    "\n",
    "# Analyze categorical features\n",
    "categorical_features = credit_risk_df.select_dtypes(include=['object']).columns\n",
    "print(\"\\nChi-square statistics for categorical features:\")\n",
    "chi2_values = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    contingency = pd.crosstab(credit_risk_df[col], credit_risk_df['default'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    chi2_values[col] = (chi2, p)\n",
    "\n",
    "sorted_categorical = sorted(chi2_values.items(), key=lambda x: x[1][0], reverse=True)\n",
    "for feature, (chi2, p) in sorted_categorical:\n",
    "    print(f\"{feature}: Chi2={chi2:.2f}, p-value={p:.6f}\")\n",
    "\n",
    "# Save to CSV\n",
    "credit_risk_df.to_csv('../data/credit_risk_dataset.csv', index=False)\n",
    "print(\"\\nDataset saved to 'credit_risk_dataset.csv'\")\n",
    "\n",
    "# Summary of highly predictive features\n",
    "print(\"\\nHighly predictive features:\")\n",
    "print(\"Numeric: income, debt_to_income_ratio, credit_score, loan_amount, interest_rate, age\")\n",
    "print(\"Correlated numeric pair: income and total_assets\")\n",
    "print(\"Categorical: employment_status, education_level, loan_purpose, has_previous_defaults\")\n",
    "print(\"Correlated categorical pair: employment_status and payment_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
