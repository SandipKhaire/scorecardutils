{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load required Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "from scorecardutils.feature_selection import (shap_feature_selection,\n",
    "                                              find_correlation_groups,\n",
    "                                              select_best_features_from_corr_groups,\n",
    "                                              vsi_check)\n",
    "from scorecardutils.BivariatePlot import unified_bivariate_analysis\n",
    "\n",
    "#from feature_engine.selection import SmartCorrelatedSelection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../data/credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure each feature has correct data types --float,int,catgeory\n",
    "for col in dev_data.select_dtypes(include='object').columns:\n",
    "    dev_data[col] = dev_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define target and features names\n",
    "target = 'default'\n",
    "features = dev_data.drop(columns=[target]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",       # For binary classification\n",
    "    \"eval_metric\": \"auc\",                 # auc\n",
    "    \"learning_rate\": 0.05,                 # Smaller means more trees; safer\n",
    "    \"max_depth\": 6,                       # Controls model complexity\n",
    "    \"subsample\": 0.8,                     # Fraction of samples per tree\n",
    "    \"colsample_bytree\": 0.8,              # Fraction of features per tree\n",
    "    \"lambda\": 1,                          # L2 regularization\n",
    "    \"alpha\": 0,                           # L1 regularization\n",
    "    \"n_estimators\": 100,                  # Total trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,importance_df,_ =shap_feature_selection(train_data=dev_data,feature_names=features,target_name='default',verbose=True,\n",
    "                                                        test_size=0.3,random_state=42,use_train_for_shap=False,\n",
    "                                                        model_params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,importance_df,shapDF =shap_feature_selection(train_data=dev_data,feature_names=selected_features,target_name='default',verbose=False,\n",
    "                                                        split_data=False,random_state=42,\n",
    "                                                        model_params=xgb_params,create_shap_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups = find_correlation_groups(shapDF, corr_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,selected_features_corr = select_best_features_from_corr_groups(correlated_groups, feature_importance_df=importance_df,\n",
    "                                      feature_importance_col='SHAP_Importance',\n",
    "                                      feature_name_col='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Binning and IV ,Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import BinningProcess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata= pd.read_csv('../data/synthetic_binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= syndata.drop(columns=[target])\n",
    "y= syndata[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars= X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract categorical and numerical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Any Special Codes to treat them in separate bucket\n",
    "e.g \n",
    "special_codes = [-999,-1,-2]\n",
    "or if need to treat separate codes with different values in different special buckets\n",
    "special_codes = {'special_1': -9, \"special_2\": -8, \"special_3\": -7}\n",
    "\"\"\"\n",
    "\n",
    "special_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Dictionary with optimal binning fitting options for specific variables. we can update it as per our customization\n",
    "for specific attributes.\n",
    "split_digits: If split_digits is set to 0, the split points are integers otherwise the split points are rounded \n",
    "to the number of digits specified by split_digits.\n",
    "user_splits: If user_splits is set, the splits are fixed to the values specified by user_splits.\n",
    "user_splits_fixed: If user_splits_fixed is set to True, the splits are fixed to the values specified by user_splits.\n",
    "monotonic_trend: If monotonic_trend is set to 'ascending', the bad rate should be non-decreasing.\n",
    "cat_cutoff:Generate bin others with categories in which the fraction of occurrences is below the cat_cutoff value. \n",
    "i.e If cat_cutoff is set to 0.05, the bin will be generated with categories in which the fraction of occurrences is below the cat_cutoff value.\n",
    "\n",
    "Initially can be passed as None. binning_fit_params=None\n",
    "\n",
    "binning_fit_params = {\n",
    "    \"dti\": {\"monotonic_trend\": \"ascending\",\"split_digits\":2 ,\n",
    "            \"user_splits\": [ 8.89, 10.91, 14.68, 16.03,18.23, 20.8 , 22.11, 28.37],\n",
    "           # \"user_splits_fixed\" :[True,True] \n",
    "           }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "binning_fit_params = {\n",
    "\n",
    "    \"loyalty_score\":{\"split_digits\":2,\n",
    "        \"user_splits\": [    -3.07959914, -2.46296906, -1.8946799 , -1.6182403 , -1 ,\n",
    "                            0,  0.37816253,  0.77244589,  1.2557528 ,\n",
    "                            1.77894938],\n",
    "        \"user_splits_fixed\": [False,False,False,False,True,True,False,False,False,False]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By default:optbinning assigns WoE = 0 and event rate = overall mean to special values (like missing or outliers), unless you override it.\n",
    "Update Strategy for Special Values:\n",
    "Strategy A: Neutralize Special Values i.e.Assign WoE = 0 (effectively no contribution to the score).\n",
    "Strategy B: Assign Empirical WoE for Special Values i.e.Let the special values’ WoE be calculated based on their actual event rate in the data.This is often used when special codes have meaningful predictive power\n",
    "Strategy C: Merge Special Value into Closest Bin. f a special code behaves like a particular bin (e.g., 999 behaves like bin [30–40]), assign its WoE manually to match that bin’s WoE\n",
    "\n",
    "binning_transform_params ={\n",
    "   'revol_util':{'metric_special':'empirical'},\n",
    "    'dti':{'metric_special': -0.306345},\n",
    "    'inq_last_6mths':{'metric_special':'empirical'}\n",
    "}\n",
    "\n",
    "or \n",
    "binning_transform_params = None\n",
    "\"\"\"\n",
    "specific_binning_transform_params = {\n",
    "    'age':{'metric_missing':'empirical','metric_special':'empirical'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define default parameter values\n",
    "default_woe_metric_missing = 0  # or whatever default you prefer\n",
    "default_woe_metric_special = 0  # or whatever default you prefer\n",
    "\n",
    "# Create a complete binning_transform_params dictionary\n",
    "binning_transform_params = {}\n",
    "\n",
    "# For each variable in model_vars\n",
    "for var in model_vars:\n",
    "    if var in specific_binning_transform_params:\n",
    "        # Use the specific parameters if defined\n",
    "        binning_transform_params[var] = specific_binning_transform_params[var]\n",
    "    else:\n",
    "        # Otherwise use default parameters\n",
    "        binning_transform_params[var] = {\n",
    "            'metric_missing': default_woe_metric_missing,\n",
    "            'metric_special': default_woe_metric_missing\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of variables to be fixed. \n",
    "The binning process will retain these variables if the selection criteria is not satisfied.\n",
    "\"\"\"\n",
    "fixed_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the selection criteria for the binning process\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01, \"max\": 0.5,\"strategy\": \"highest\", \"top\": 50},\n",
    "    \"quality_score\": {\"min\": 0.01}\n",
    "}\n",
    "\n",
    "or \n",
    "selection_criteria = None\n",
    "\"\"\"\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01}#\"strategy\": \"highest\", \"top\": 11\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_process = BinningProcess(variable_names=model_vars, special_codes=special_codes,\n",
    "                                 categorical_variables=categorical_columns,\n",
    "                                 selection_criteria=selection_criteria,\n",
    "                                 binning_fit_params=binning_fit_params,\n",
    "                                 binning_transform_params=binning_transform_params,\n",
    "                                fixed_variables=fixed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the binning process    \n",
    "binning_process.fit(X=X_train[model_vars], y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save all the variables passed to binning process and their IVs for manual screening\n",
    "iv_tab=binning_process.summary().sort_values(by='iv',ascending=False)\n",
    "#iv_tab.to_excel('iv_tab.xlsx', index=False)\n",
    "iv_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_selected_variables = iv_tab[iv_tab['iv']>0.02]['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see any specific variable binning table\n",
    "optb = binning_process.get_binned_variable('age')\n",
    "df = optb.binning_table.build()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSI summary\n",
    "csi_summ = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='summary',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "## CSI detailed Summary\n",
    "csi_det = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='detailed',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save csi in excel\n",
    "with pd.ExcelWriter('csi.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    csi_summ.to_excel(writer, sheet_name='summary', index=False)\n",
    "    csi_det.to_excel(writer, sheet_name='detail', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stable variables (PSI < threshold)\n",
    "stable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] < 10]['Variable'].tolist()]\n",
    "    \n",
    "# Filter unstable variables (PSI >= threshold)\n",
    "unstable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] >= 10]['Variable'].tolist()]\n",
    "print(\"Unstable Variables:\", unstable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs = [feature for feature in iv_selected_variables if feature not in unstable_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bivariate plot on both Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing training data with a newer time period\n",
    "unified_bivariate_analysis(\n",
    "    binning_process=binning_process,\n",
    "    filename='event_rate_train',\n",
    "    metric='woe',\n",
    "    oot_data= None,  # Data from a more recent time period\n",
    "    target_column=target,\n",
    "    compare_data=False ,\n",
    "    variables=selected_features_ivs,\n",
    "    show_bar_values=True ,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transofrm variables to WoE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe = binning_process.transform(X=X_train,metric='woe')\n",
    "X_test_woe = binning_process.transform(X=X_test,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_woe.shape)\n",
    "print(X_test_woe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of final selected variables\n",
    "final_predictors=list(binning_process.get_support(names=True))\n",
    "#final_predictors = ['loyalty_score','credit_score','customer_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into woe or binned values or event rate\n",
    "X_train_WOE = binning_process.transform(X_train,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example to understand the how binning object trasform the data to woe values\n",
    "test_exmaple = pd.DataFrame([{'age': -999,\n",
    " 'income': -0.8276048978295478,\n",
    " 'experience_years': -0.7913895315832409,\n",
    " 'credit_score': -0.7389923463082454,\n",
    " 'avg_spend': 0.7331633070112105,\n",
    " 'loyalty_score': -0.8702525202009143,\n",
    " 'satisfaction_rating': 2.237864030340072,\n",
    " 'demographic_index': -0.3085181724416579,\n",
    " 'financial_status': -0.0191376466062278,\n",
    " 'work_experience': -1.812865565832083,\n",
    " 'credit_index': 0.5505331954414358,\n",
    " 'customer_group': 'group_B'}])\n",
    "\n",
    "test_WOE = binning_process.transform(test_exmaple,metric='woe')\n",
    "test_WOE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
