{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load required Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "from scorecardutils.feature_selection import (shap_feature_selection,\n",
    "                                              find_correlation_groups,\n",
    "                                              select_best_features_from_corr_groups,\n",
    "                                              vsi_check)\n",
    "\n",
    "#from feature_engine.selection import SmartCorrelatedSelection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../data/credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure each feature has correct data types --float,int,catgeory\n",
    "for col in dev_data.select_dtypes(include='object').columns:\n",
    "    dev_data[col] = dev_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define target and features names\n",
    "target = 'default'\n",
    "features = dev_data.drop(columns=[target]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",       # For binary classification\n",
    "    \"eval_metric\": \"auc\",                 # auc\n",
    "    \"learning_rate\": 0.05,                 # Smaller means more trees; safer\n",
    "    \"max_depth\": 6,                       # Controls model complexity\n",
    "    \"subsample\": 0.8,                     # Fraction of samples per tree\n",
    "    \"colsample_bytree\": 0.8,              # Fraction of features per tree\n",
    "    \"lambda\": 1,                          # L2 regularization\n",
    "    \"alpha\": 0,                           # L1 regularization\n",
    "    \"n_estimators\": 100,                  # Total trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,importance_df,_ =shap_feature_selection(train_data=dev_data,feature_names=features,target_name='default',verbose=True,\n",
    "                                                        test_size=0.3,random_state=42,use_train_for_shap=False,\n",
    "                                                        model_params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,importance_df,shapDF =shap_feature_selection(train_data=dev_data,feature_names=selected_features,target_name='default',verbose=False,\n",
    "                                                        split_data=False,random_state=42,\n",
    "                                                        model_params=xgb_params,create_shap_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups = find_correlation_groups(shapDF, corr_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,selected_features_corr = select_best_features_from_corr_groups(correlated_groups, feature_importance_df=importance_df,\n",
    "                                      feature_importance_col='SHAP_Importance',\n",
    "                                      feature_name_col='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Binning and IV ,Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import BinningProcess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata= pd.read_csv('../data/synthetic_binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= syndata.drop(columns=[target])\n",
    "y= syndata[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars= X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract categorical and numerical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Any Special Codes to treat them in separate bucket\n",
    "e.g \n",
    "special_codes = [-999,-1,-2]\n",
    "or if need to treat separate codes with different values in different special buckets\n",
    "special_codes = {'special_1': -9, \"special_2\": -8, \"special_3\": -7}\n",
    "\"\"\"\n",
    "\n",
    "special_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Dictionary with optimal binning fitting options for specific variables. we can update it as per our customization\n",
    "for specific attributes.\n",
    "split_digits: If split_digits is set to 0, the split points are integers otherwise the split points are rounded \n",
    "to the number of digits specified by split_digits.\n",
    "user_splits: If user_splits is set, the splits are fixed to the values specified by user_splits.\n",
    "user_splits_fixed: If user_splits_fixed is set to True, the splits are fixed to the values specified by user_splits.\n",
    "monotonic_trend: If monotonic_trend is set to 'ascending', the bad rate should be non-decreasing.\n",
    "cat_cutoff:Generate bin others with categories in which the fraction of occurrences is below the cat_cutoff value. \n",
    "i.e If cat_cutoff is set to 0.05, the bin will be generated with categories in which the fraction of occurrences is below the cat_cutoff value.\n",
    "\n",
    "Initially can be passed as None. binning_fit_params=None\n",
    "\n",
    "binning_fit_params = {\n",
    "    \"dti\": {\"monotonic_trend\": \"ascending\",\"split_digits\":2 ,\n",
    "            \"user_splits\": [ 8.89, 10.91, 14.68, 16.03,18.23, 20.8 , 22.11, 28.37],\n",
    "           # \"user_splits_fixed\" :[True,True] \n",
    "           }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "binning_fit_params = {\n",
    "\n",
    "    \"loyalty_score\":{\"split_digits\":2,\n",
    "        \"user_splits\": [    -3.07959914, -2.46296906, -1.8946799 , -1.6182403 , -1 ,\n",
    "                            0,  0.37816253,  0.77244589,  1.2557528 ,\n",
    "                            1.77894938],\n",
    "        \"user_splits_fixed\": [False,False,False,False,True,True,False,False,False,False]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By default:optbinning assigns WoE = 0 and event rate = overall mean to special values (like missing or outliers), unless you override it.\n",
    "Update Strategy for Special Values:\n",
    "Strategy A: Neutralize Special Values i.e.Assign WoE = 0 (effectively no contribution to the score).\n",
    "Strategy B: Assign Empirical WoE for Special Values i.e.Let the special values’ WoE be calculated based on their actual event rate in the data.This is often used when special codes have meaningful predictive power\n",
    "Strategy C: Merge Special Value into Closest Bin. f a special code behaves like a particular bin (e.g., 999 behaves like bin [30–40]), assign its WoE manually to match that bin’s WoE\n",
    "\n",
    "binning_transform_params ={\n",
    "   'revol_util':{'metric_special':'empirical'},\n",
    "    'dti':{'metric_special': -0.306345},\n",
    "    'inq_last_6mths':{'metric_special':'empirical'}\n",
    "}\n",
    "\n",
    "or \n",
    "binning_transform_params = None\n",
    "\"\"\"\n",
    "binning_transform_params = {\n",
    "    'age':{'metric_missing':'empirical','metric_special':'empirical'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of variables to be fixed. \n",
    "The binning process will retain these variables if the selection criteria is not satisfied.\n",
    "\"\"\"\n",
    "fixed_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the selection criteria for the binning process\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01, \"max\": 0.5,\"strategy\": \"highest\", \"top\": 50},\n",
    "    \"quality_score\": {\"min\": 0.01}\n",
    "}\n",
    "\n",
    "or \n",
    "selection_criteria = None\n",
    "\"\"\"\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01,\"strategy\": \"highest\", \"top\": 50}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_process = BinningProcess(variable_names=model_vars, special_codes=special_codes,\n",
    "                                 categorical_variables=categorical_columns,\n",
    "                                 selection_criteria=selection_criteria,\n",
    "                                 binning_fit_params=binning_fit_params,\n",
    "                                 binning_transform_params=binning_transform_params,\n",
    "                                fixed_variables=fixed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the binning process    \n",
    "binning_process.fit(X=X_train[model_vars], y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save all the variables passed to binning process and their IVs for manual screening\n",
    "iv_tab=binning_process.summary().sort_values(by='iv',ascending=False)\n",
    "#iv_tab.to_excel('iv_tab.xlsx', index=False)\n",
    "iv_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_selected_variables = iv_tab[iv_tab['iv']>0.02]['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_selected_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see any specific variable binning table\n",
    "optb = binning_process.get_binned_variable('customer_group')\n",
    "df = optb.binning_table.build()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSI summary\n",
    "csi_summ = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='summary',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "## CSI detailed Summary\n",
    "csi_det = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='detailed',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save csi in excel\n",
    "with pd.ExcelWriter('csi.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    csi_summ.to_excel(writer, sheet_name='summary', index=False)\n",
    "    csi_det.to_excel(writer, sheet_name='detail', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stable variables (PSI < threshold)\n",
    "stable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] < 10]['Variable'].tolist()]\n",
    "    \n",
    "# Filter unstable variables (PSI >= threshold)\n",
    "unstable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] >= 10]['Variable'].tolist()]\n",
    "print(\"Unstable Variables:\", unstable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs = [feature for feature in iv_selected_variables if feature not in unstable_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bivariate plot on both Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is scope of improvement like currently plot is getting cropped so using seaborn we can customized\n",
    "def bivariate_plot(filename='bivariate',binning_process=binning_process,metric_='event_rate'):\n",
    "    with pd.ExcelWriter(f'{filename}.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        for var in binning_process.get_support(names=True):\n",
    "            optb = binning_process.get_binned_variable(var)\n",
    "            \n",
    "            # Get DataFrame from binning table\n",
    "            df = optb.binning_table.build()\n",
    "            df = df.drop(columns='JS')\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            # Write DataFrame to Excel\n",
    "            df.to_excel(writer, sheet_name=var, index=False)\n",
    "            # Plotting\n",
    "            plot_image_path = f'variable_{var}_plot.png'\n",
    "            optb.binning_table.plot(metric=metric_, show_bin_labels=True,savefig=plot_image_path,figsize=(10, 10))\n",
    "            #plt.close()\n",
    "    \n",
    "            # Insert plot image into the Excel sheet\n",
    "            img = Image(plot_image_path)\n",
    "            img.anchor = f'K1'  # Adjust the anchor cell as needed\n",
    "            writer.sheets[var].add_image(img)\n",
    "    \n",
    "    for var in binning_process.get_support(names=True):\n",
    "        plot_image_path = f'variable_{var}_plot.png'\n",
    "        os.remove(plot_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_plot(metric_='woe',filename='bivariate_woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optb = binning_process.get_binned_variable('age')\n",
    "\n",
    "# Get DataFrame from binning table\n",
    "df = optb.binning_table.build()\n",
    "df = df.drop(columns='JS')\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from openpyxl.drawing.image import Image\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "\n",
    "def enhanced_bivariate_plot(\n",
    "    binning_process,\n",
    "    filename: str = 'bivariate',\n",
    "    metric: str = 'event_rate',\n",
    "    variables: Optional[List[str]] = None,\n",
    "    figsize: tuple = (12, 6),  # Reduced figure size for better viewing\n",
    "    dpi: int = 100,\n",
    "    style: str = 'whitegrid'\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create enhanced bivariate plots and export to Excel with special handling for \n",
    "    Totals (in index column), Special, and Missing bins.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    binning_process : OptimalBinning process object\n",
    "        The binning process containing the variables to plot\n",
    "    filename : str, default='bivariate'\n",
    "        Base name for the output Excel file\n",
    "    metric : str, default='event_rate'\n",
    "        Metric to plot. Options: 'event_rate', 'woe'\n",
    "    variables : list of str, optional\n",
    "        List of specific variable names to process. If None, all variables are processed.\n",
    "    figsize : tuple, default=(14, 8)\n",
    "        Figure size for plots in inches (width, height)\n",
    "    dpi : int, default=300\n",
    "        Resolution of saved images\n",
    "    style : str, default='whitegrid'\n",
    "        Seaborn style for plots\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Saves Excel file with embedded plots and data tables\n",
    "    \"\"\"\n",
    "    # Validate metric parameter\n",
    "    metric = metric.lower()\n",
    "    if metric not in ['event_rate', 'woe']:\n",
    "        raise ValueError(\"metric must be either 'event_rate' or 'woe'\")\n",
    "    \n",
    "    # Get all available variables from binning process\n",
    "    all_variables = binning_process.get_support(names=True)\n",
    "    \n",
    "    # Filter variables if specified\n",
    "    if variables is not None:\n",
    "        # Check if all specified variables exist in the binning process\n",
    "        invalid_vars = set(variables) - set(all_variables)\n",
    "        if invalid_vars:\n",
    "            raise ValueError(f\"Variables not found in binning process: {', '.join(invalid_vars)}\")\n",
    "        selected_vars = variables\n",
    "    else:\n",
    "        selected_vars = all_variables\n",
    "    \n",
    "    # Set up the visualization style\n",
    "    #sns.set_style(style)\n",
    "    plt.style.use('default')  # Clean matplotlib style\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create a temporary directory for images if it doesn't exist\n",
    "    if not os.path.exists('temp_plots'):\n",
    "        os.makedirs('temp_plots')\n",
    "    \n",
    "    # Dictionary to store plot paths\n",
    "    plot_paths = {}\n",
    "    \n",
    "    # Determine column names based on metric\n",
    "    metric_column = 'Event rate' if metric == 'event_rate' else 'WoE'\n",
    "    y_axis_label = 'Event Rate' if metric == 'event_rate' else 'Weight of Evidence (WoE)'\n",
    "    \n",
    "    # Create Excel writer\n",
    "    with pd.ExcelWriter(f'{filename}.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "        # Process each selected variable\n",
    "        for var in selected_vars:\n",
    "            # Get the binned variable\n",
    "            optb = binning_process.get_binned_variable(var)\n",
    "            \n",
    "            # Get DataFrame from binning table and clean it up\n",
    "            df = optb.binning_table.build()\n",
    "            #df[\"Event rate\"] = (df[\"Event rate\"] * 100).round(1)\n",
    "            if 'JS' in df.columns:\n",
    "                df = df.drop(columns='JS')\n",
    "            \n",
    "            # Keep the original DataFrame for Excel output including Totals row\n",
    "            df_for_excel = df.reset_index()\n",
    "            \n",
    "            # Extract the Totals row and remove it from the main DataFrame for plotting\n",
    "            totals_row = None\n",
    "            if 'Totals' in df.index:\n",
    "                totals_row = df.loc['Totals']\n",
    "                df = df.drop('Totals')\n",
    "            \n",
    "            # Reset index after removing Totals, making the index into a column\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            # The actual bin column is 'Bin', but if it doesn't exist, use the first column as fallback\n",
    "            bin_col_name = 'Bin' if 'Bin' in df.columns else df.columns[0]\n",
    "            \n",
    "            # Write original DataFrame (including Totals) to Excel\n",
    "            df_for_excel.to_excel(writer, sheet_name=var, index=False)\n",
    "            \n",
    "            # Create custom plot using Seaborn and Matplotlib\n",
    "            plot_image_path = f'temp_plots/variable_{var}_{metric}.png'\n",
    "            \n",
    "            # Create figure with proper size to avoid cropping\n",
    "            fig, ax1 = plt.subplots(figsize=figsize)\n",
    "            \n",
    "            # Identify regular, special, and missing bins\n",
    "            # Explicitly check for strings 'Special' and 'Missing' in the bins column\n",
    "            regular_bins = df[(df[bin_col_name] != 'Special') & (df[bin_col_name] != 'Missing')]\n",
    "            special_bin = df[df[bin_col_name] == 'Special'] if 'Special' in df[bin_col_name].values else pd.DataFrame()\n",
    "            missing_bin = df[df[bin_col_name] == 'Missing'] if 'Missing' in df[bin_col_name].values else pd.DataFrame()\n",
    "            \n",
    "            # Create indices for x-axis\n",
    "            x_indices = np.arange(len(df))\n",
    "            \n",
    "            # Format bin labels for better display\n",
    "            bin_labels = []\n",
    "            for _, row in df.iterrows():\n",
    "                bin_name = row[bin_col_name]\n",
    "                if bin_name in ['Special', 'Missing']:\n",
    "                    bin_labels.append(bin_name)\n",
    "                else:\n",
    "                    # Use the actual bin values but truncate if too long\n",
    "                    shortened_name = str(bin_name)\n",
    "                    if len(shortened_name) > 15:\n",
    "                        shortened_name = shortened_name[:12] + \"...\"\n",
    "                    bin_labels.append(shortened_name)\n",
    "            \n",
    "            # Plot Count (%) as blue bars for all bins\n",
    "            bars = ax1.bar(x_indices, df['Count (%)'] * 100, color='#0a3f7d', alpha=0.7)\n",
    "            ax1.set_xticks(x_indices)\n",
    "            ax1.set_xticklabels(bin_labels, rotation=45, ha='right', fontsize=9)\n",
    "            ax1.set_xlabel('Bins', fontsize=10)\n",
    "            ax1.set_ylabel('Count (%)', color='blue', fontsize=10)\n",
    "            ax1.tick_params(axis='y', labelcolor='blue', labelsize=9)\n",
    "            \n",
    "            # Create second y-axis for Event Rate or WoE\n",
    "            ax2 = ax1.twinx()\n",
    "            line_color = 'darkgoldenrod'\n",
    "            \n",
    "            # Plot the metric line for regular bins only (connecting them)\n",
    "            if not regular_bins.empty:\n",
    "                # Get indices of regular bins in the full dataframe\n",
    "                regular_mask = df[bin_col_name].apply(lambda x: x not in ['Special', 'Missing'])\n",
    "                regular_indices = np.where(regular_mask)[0]\n",
    "                \n",
    "                if len(regular_indices) > 0:\n",
    "                    # Plot connected line for regular bins\n",
    "                    ax2.plot(regular_indices, regular_bins[metric_column], \n",
    "                             marker='o', color=line_color, linewidth=2, label=y_axis_label)\n",
    "                    \n",
    "                    # Add value annotations for regular bins with smaller font\n",
    "                    for idx, val in zip(regular_indices, regular_bins[metric_column]):\n",
    "                        ax2.annotate(f'{val:.3f}', \n",
    "                                     xy=(idx, val), \n",
    "                                     xytext=(0, 5),\n",
    "                                     textcoords='offset points',\n",
    "                                     ha='center', \n",
    "                                     fontsize=7)\n",
    "            \n",
    "            # Plot Special bin point (if exists) without connecting\n",
    "            if not special_bin.empty:\n",
    "                special_idx = df[df[bin_col_name] == 'Special'].index[0]\n",
    "                special_val = special_bin[metric_column].values[0]\n",
    "                ax2.plot(special_idx, special_val,\n",
    "                         marker='s', color='red', markersize=8, linestyle='None', label='Special')\n",
    "                # Reduce decimal places and font size for special bin annotation\n",
    "                ax2.annotate(f'{special_val:.3f}', \n",
    "                             xy=(special_idx, special_val), \n",
    "                             xytext=(0, 5),\n",
    "                             textcoords='offset points',\n",
    "                             ha='center', \n",
    "                             fontsize=7)\n",
    "            \n",
    "            # Plot Missing bin point (if exists) without connecting\n",
    "            if not missing_bin.empty:\n",
    "                missing_idx = df[df[bin_col_name] == 'Missing'].index[0]\n",
    "                missing_val = missing_bin[metric_column].values[0]\n",
    "                ax2.plot(missing_idx, missing_val,\n",
    "                         marker='D', color='purple', markersize=8, linestyle='None', label='Missing')\n",
    "                # Reduce decimal places and font size for missing bin annotation\n",
    "                ax2.annotate(f'{missing_val:.3f}', \n",
    "                             xy=(missing_idx, missing_val), \n",
    "                             xytext=(0, 5),\n",
    "                             textcoords='offset points',\n",
    "                             ha='center', \n",
    "                             fontsize=7)\n",
    "            \n",
    "            # Add horizontal line for Totals if available\n",
    "            if totals_row is not None:\n",
    "                total_metric_value = totals_row[metric_column]\n",
    "                \n",
    "                # Handle case where WoE might be a blank string in Totals row\n",
    "                if isinstance(total_metric_value, str) and total_metric_value.strip() == '':\n",
    "                    total_metric_value = 0.0\n",
    "                else:\n",
    "                    # Try to convert to float in case it's a string representation of a number\n",
    "                    try:\n",
    "                        total_metric_value = float(total_metric_value)\n",
    "                    except (ValueError, TypeError):\n",
    "                        total_metric_value = 0.0\n",
    "                \n",
    "                ax2.axhline(y=total_metric_value, color='green', linestyle='--', \n",
    "                           alpha=0.7, label=f'Total {y_axis_label}: {total_metric_value:.4f}')\n",
    "            \n",
    "            # Set y-axis label and title\n",
    "            ax2.set_ylabel(y_axis_label, color=line_color, fontsize=11)\n",
    "            ax2.tick_params(axis='y', labelcolor=line_color)\n",
    "            \n",
    "            # Set title with variable name but keep it concise\n",
    "            plt.title(f'{var}: {y_axis_label} by Bin', fontsize=12)\n",
    "            \n",
    "            # Add legend with small font size and optimize position\n",
    "            lines, labels = ax2.get_legend_handles_labels()\n",
    "            ax2.legend(lines, labels, loc='best', fontsize=9)\n",
    "            \n",
    "            # Add grid for better visualization\n",
    "            #ax1.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            # Adjust layout to prevent cropping\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save the figure with high quality\n",
    "            plt.savefig(plot_image_path, dpi=dpi, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            # Store the path for later cleanup\n",
    "            plot_paths[var] = plot_image_path\n",
    "            \n",
    "            # Insert plot image into the Excel sheet\n",
    "            img = Image(plot_image_path)\n",
    "            \n",
    "            # Calculate position based on data size (including Totals row)\n",
    "            # Start plot after the data table with some margin\n",
    "            row_position = len(df_for_excel) + 4  # +4 for margin\n",
    "            img.anchor = f'A{row_position}'\n",
    "            \n",
    "            writer.sheets[var].add_image(img)\n",
    "            \n",
    "            # Adjust column widths for better readability\n",
    "            for idx, col in enumerate(df_for_excel.columns):\n",
    "                column_width = max(len(str(col)), df_for_excel[col].astype(str).map(len).max())\n",
    "                writer.sheets[var].column_dimensions[chr(65 + idx)].width = column_width + 2\n",
    "    \n",
    "    # Clean up temporary image files\n",
    "    for path in plot_paths.values():\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "    \n",
    "    # Remove temp directory if empty\n",
    "    if os.path.exists('temp_plots') and not os.listdir('temp_plots'):\n",
    "        os.rmdir('temp_plots')\n",
    "    \n",
    "    print(f\"Enhanced bivariate analysis completed! Results saved to {filename}.xlsx\")\n",
    "\n",
    "\n",
    "# Example usage with different metrics and variable selections\n",
    "# 1. Process all variables with event rate\n",
    "# enhanced_bivariate_plot(binning_process, filename='bivariate_event_rate', metric='event_rate')\n",
    "\n",
    "# 2. Process all variables with WoE\n",
    "# enhanced_bivariate_plot(binning_process, filename='bivariate_woe', metric='woe')\n",
    "\n",
    "# 3. Process only specific variables\n",
    "# enhanced_bivariate_plot(\n",
    "#     binning_process, \n",
    "#     filename='selected_variables', \n",
    "#     metric='event_rate',\n",
    "#     variables=['age', 'income', 'credit_score']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_bivariate_plot(\n",
    " binning_process, \n",
    "filename='selected_variables', \n",
    " metric='event_rate',\n",
    "variables=['age', 'income', 'customer_group'],\n",
    "figsize = (12, 6),\n",
    "dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of final selected variables\n",
    "final_predictors=list(binning_process.get_support(names=True))\n",
    "#final_predictors = ['loyalty_score','credit_score','customer_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into woe or binned values or event rate\n",
    "X_train_WOE = binning_process.transform(X_train,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example to understand the how binning object trasform the data to woe values\n",
    "test_exmaple = pd.DataFrame([{'age': -999,\n",
    " 'income': -0.8276048978295478,\n",
    " 'experience_years': -0.7913895315832409,\n",
    " 'credit_score': -0.7389923463082454,\n",
    " 'avg_spend': 0.7331633070112105,\n",
    " 'loyalty_score': -0.8702525202009143,\n",
    " 'satisfaction_rating': 2.237864030340072,\n",
    " 'demographic_index': -0.3085181724416579,\n",
    " 'financial_status': -0.0191376466062278,\n",
    " 'work_experience': -1.812865565832083,\n",
    " 'credit_index': 0.5505331954414358,\n",
    " 'customer_group': 'group_B'}])\n",
    "\n",
    "test_WOE = binning_process.transform(test_exmaple,metric='woe')\n",
    "test_WOE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
