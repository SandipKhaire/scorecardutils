{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load required Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "from scorecardutils.feature_selection import (shap_feature_selection,\n",
    "                                              find_correlation_groups,\n",
    "                                              select_best_features_from_corr_groups,\n",
    "                                              vsi_check)\n",
    "from scorecardutils.BivariatePlot import unified_bivariate_analysis\n",
    "\n",
    "#from feature_engine.selection import SmartCorrelatedSelection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../data/credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure each feature has correct data types --float,int,catgeory\n",
    "for col in dev_data.select_dtypes(include='object').columns:\n",
    "    dev_data[col] = dev_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define target and features names\n",
    "target = 'default'\n",
    "features = dev_data.drop(columns=[target]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",       # For binary classification\n",
    "    \"eval_metric\": \"auc\",                 # auc\n",
    "    \"learning_rate\": 0.05,                 # Smaller means more trees; safer\n",
    "    \"max_depth\": 6,                       # Controls model complexity\n",
    "    \"subsample\": 0.8,                     # Fraction of samples per tree\n",
    "    \"colsample_bytree\": 0.8,              # Fraction of features per tree\n",
    "    \"lambda\": 1,                          # L2 regularization\n",
    "    \"alpha\": 0,                           # L1 regularization\n",
    "    \"n_estimators\": 100,                  # Total trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,importance_df,_ =shap_feature_selection(train_data=dev_data,feature_names=features,target_name='default',verbose=True,\n",
    "                                                        test_size=0.3,random_state=42,use_train_for_shap=False,\n",
    "                                                        model_params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,importance_df,shapDF =shap_feature_selection(train_data=dev_data,feature_names=selected_features,target_name='default',verbose=False,\n",
    "                                                        split_data=False,random_state=42,\n",
    "                                                        model_params=xgb_params,create_shap_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups = find_correlation_groups(shapDF, corr_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,selected_features_corr = select_best_features_from_corr_groups(correlated_groups, feature_importance_df=importance_df,\n",
    "                                      feature_importance_col='SHAP_Importance',\n",
    "                                      feature_name_col='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Binning and IV ,Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import BinningProcess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata= pd.read_csv('../data/synthetic_binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= syndata.drop(columns=[target])\n",
    "y= syndata[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars= X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract categorical and numerical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Any Special Codes to treat them in separate bucket\n",
    "e.g \n",
    "special_codes = [-999,-1,-2]\n",
    "or if need to treat separate codes with different values in different special buckets\n",
    "special_codes = {'special_1': -9, \"special_2\": -8, \"special_3\": -7}\n",
    "\"\"\"\n",
    "\n",
    "special_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Dictionary with optimal binning fitting options for specific variables. we can update it as per our customization\n",
    "for specific attributes.\n",
    "split_digits: If split_digits is set to 0, the split points are integers otherwise the split points are rounded \n",
    "to the number of digits specified by split_digits.\n",
    "user_splits: If user_splits is set, the splits are fixed to the values specified by user_splits.\n",
    "user_splits_fixed: If user_splits_fixed is set to True, the splits are fixed to the values specified by user_splits.\n",
    "monotonic_trend: If monotonic_trend is set to 'ascending', the bad rate should be non-decreasing.\n",
    "cat_cutoff:Generate bin others with categories in which the fraction of occurrences is below the cat_cutoff value. \n",
    "i.e If cat_cutoff is set to 0.05, the bin will be generated with categories in which the fraction of occurrences is below the cat_cutoff value.\n",
    "\n",
    "Initially can be passed as None. binning_fit_params=None\n",
    "\n",
    "binning_fit_params = {\n",
    "    \"dti\": {\"monotonic_trend\": \"ascending\",\"split_digits\":2 ,\n",
    "            \"user_splits\": [ 8.89, 10.91, 14.68, 16.03,18.23, 20.8 , 22.11, 28.37],\n",
    "           # \"user_splits_fixed\" :[True,True] \n",
    "           }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "binning_fit_params = {\n",
    "\n",
    "    \"loyalty_score\":{\"split_digits\":2,\n",
    "        \"user_splits\": [    -3.07959914, -2.46296906, -1.8946799 , -1.6182403 , -1 ,\n",
    "                            0,  0.37816253,  0.77244589,  1.2557528 ,\n",
    "                            1.77894938],\n",
    "        \"user_splits_fixed\": [False,False,False,False,True,True,False,False,False,False]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By default:optbinning assigns WoE = 0 and event rate = overall mean to special values (like missing or outliers), unless you override it.\n",
    "Update Strategy for Special Values:\n",
    "Strategy A: Neutralize Special Values i.e.Assign WoE = 0 (effectively no contribution to the score).\n",
    "Strategy B: Assign Empirical WoE for Special Values i.e.Let the special valuesâ€™ WoE be calculated based on their actual event rate in the data.This is often used when special codes have meaningful predictive power\n",
    "Strategy C: Merge Special Value into Closest Bin. f a special code behaves like a particular bin (e.g., 999 behaves like bin [30â€“40]), assign its WoE manually to match that binâ€™s WoE\n",
    "\n",
    "binning_transform_params ={\n",
    "   'revol_util':{'metric_special':'empirical'},\n",
    "    'dti':{'metric_special': -0.306345},\n",
    "    'inq_last_6mths':{'metric_special':'empirical'}\n",
    "}\n",
    "\n",
    "or \n",
    "binning_transform_params = None\n",
    "\"\"\"\n",
    "specific_binning_transform_params = {\n",
    "    'age':{'metric_missing':'empirical','metric_special':'empirical'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define default parameter values\n",
    "default_woe_metric_missing = 0  # or whatever default you prefer\n",
    "default_woe_metric_special = 0  # or whatever default you prefer\n",
    "\n",
    "# Create a complete binning_transform_params dictionary\n",
    "binning_transform_params = {}\n",
    "\n",
    "# For each variable in model_vars\n",
    "for var in model_vars:\n",
    "    if var in specific_binning_transform_params:\n",
    "        # Use the specific parameters if defined\n",
    "        binning_transform_params[var] = specific_binning_transform_params[var]\n",
    "    else:\n",
    "        # Otherwise use default parameters\n",
    "        binning_transform_params[var] = {\n",
    "            'metric_missing': default_woe_metric_missing,\n",
    "            'metric_special': default_woe_metric_missing\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of variables to be fixed. \n",
    "The binning process will retain these variables if the selection criteria is not satisfied.\n",
    "\"\"\"\n",
    "fixed_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the selection criteria for the binning process\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01, \"max\": 0.5,\"strategy\": \"highest\", \"top\": 50},\n",
    "    \"quality_score\": {\"min\": 0.01}\n",
    "}\n",
    "\n",
    "or \n",
    "selection_criteria = None\n",
    "\"\"\"\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01}#\"strategy\": \"highest\", \"top\": 11\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_process = BinningProcess(variable_names=model_vars, special_codes=special_codes,\n",
    "                                 categorical_variables=categorical_columns,\n",
    "                                 selection_criteria=selection_criteria,\n",
    "                                 binning_fit_params=binning_fit_params,\n",
    "                                 binning_transform_params=binning_transform_params,\n",
    "                                fixed_variables=fixed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the binning process    \n",
    "binning_process.fit(X=X_train[model_vars], y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save all the variables passed to binning process and their IVs for manual screening\n",
    "iv_tab=binning_process.summary().sort_values(by='iv',ascending=False)\n",
    "#iv_tab.to_excel('iv_tab.xlsx', index=False)\n",
    "iv_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_selected_variables = iv_tab[iv_tab['iv']>0.02]['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see any specific variable binning table\n",
    "optb = binning_process.get_binned_variable('age')\n",
    "df = optb.binning_table.build()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSI summary\n",
    "csi_summ = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='summary',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "## CSI detailed Summary\n",
    "csi_det = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='detailed',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save csi in excel\n",
    "with pd.ExcelWriter('csi.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    csi_summ.to_excel(writer, sheet_name='summary', index=False)\n",
    "    csi_det.to_excel(writer, sheet_name='detail', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stable variables (PSI < threshold)\n",
    "stable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] < 10]['Variable'].tolist()]\n",
    "    \n",
    "# Filter unstable variables (PSI >= threshold)\n",
    "unstable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] >= 10]['Variable'].tolist()]\n",
    "print(\"Unstable Variables:\", unstable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs = [feature for feature in iv_selected_variables if feature not in unstable_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bivariate plot on both Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing training data with a newer time period\n",
    "unified_bivariate_analysis(\n",
    "    binning_process=binning_process,\n",
    "    filename='event_rate_train',\n",
    "    metric='woe',\n",
    "    oot_data= None,  # Data from a more recent time period\n",
    "    target_column=target,\n",
    "    compare_data=False ,\n",
    "    variables=selected_features_ivs,\n",
    "    show_bar_values=True ,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transofrm variables to WoE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe = binning_process.transform(X=X_train,metric='woe')\n",
    "X_test_woe = binning_process.transform(X=X_test,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_woe.shape)\n",
    "print(X_test_woe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "from scorecardutils.feature_selection import (shap_feature_selection,\n",
    "                                              find_correlation_groups,\n",
    "                                              select_best_features_from_corr_groups,\n",
    "                                              vsi_check)\n",
    "from scorecardutils.BivariatePlot import unified_bivariate_analysis\n",
    "import xgboost as xgb\n",
    "#from feature_engine.selection import SmartCorrelatedSelection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata= pd.read_csv('../data/synthetic_binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract categorical and numerical columns\n",
    "categorical_columns = syndata.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_columns = syndata.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata[categorical_columns] = syndata[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= syndata.drop(columns=[target])\n",
    "y= syndata[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "#train_data = pd.concat([X_train, y_train], axis=1)\n",
    "#test_data = pd.concat([X_test, y_test], axis=1)\n",
    "#train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list =['loyalty_score',\n",
    " 'satisfaction_rating',\n",
    " 'avg_spend',\n",
    " 'work_experience',\n",
    " 'experience_years',\n",
    " 'customer_group',\n",
    " 'income',\n",
    " 'credit_score',\n",
    " 'financial_status',\n",
    " 'demographic_index',\n",
    " 'age',\n",
    " 'credit_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with scikit-learn API\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    learning_rate=0.01,\n",
    "    max_depth=4,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method='hist',\n",
    "    scale_pos_weight=sum(y_train==0)/sum(y_train==1),\n",
    "    enable_categorical=True,  # Enable categorical features\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],  \n",
    "    verbose=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To save the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorecardutils.utils import save_object,load_object,eqLinear,three_digit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_object(obj = model,file_path = 'xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create single dataframe with train/test/OOT data and their proablities of default and three digit score with dataset segment\n",
    "\n",
    "# create a DataFrame for train data\n",
    "df_train = X_train.copy()\n",
    "df_train['target'] = y_train\n",
    "y_pred_prob_train = model.predict_proba(X_train)[:, 1] # probability of default\n",
    "df_train['pred_prob'] = y_pred_prob_train\n",
    "df_train['dataset'] = 'train'\n",
    "print(df_train.shape)\n",
    "\n",
    "# create a DataFrame for test data\n",
    "df_test = X_test.copy()\n",
    "df_test['target'] = y_test\n",
    "y_pred_prob_test = model.predict_proba(X_test)[:, 1] # probability of default\n",
    "df_test['pred_prob'] = y_pred_prob_test\n",
    "df_test['dataset'] = 'test'\n",
    "print(df_test.shape)\n",
    "\n",
    "# create a DataFrame for oot data\n",
    "#df_oot = X_oot.copy()\n",
    "#df_oot['target'] = y_oot\n",
    "#y_pred_prob_oot = model.predict_proba(X_oot)[:, 1] # probability of default\n",
    "#df_oot['pred_prob'] = y_pred_prob_oot\n",
    "#df_oot['dataset'] = 'oot'\n",
    "\n",
    "#combine all dataframes\n",
    "df_all = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "#3 digit score conversion\n",
    "base_pd = df_train.target.mean() # Reference probability of default at middle score i.e. at 600 (300,900)\n",
    "OddsAtAnchor = (1-base_pd)/base_pd\n",
    "eqLinParams = eqLinear(OddsAtAnchor=OddsAtAnchor,Anchor=600,PDO=20)\n",
    "alpha = eqLinParams['alpha']\n",
    "beta  = eqLinParams['beta']\n",
    "# Apply score conversion\n",
    "df_all['score'] = three_digit_score(df_all['pred_prob'], alpha=alpha, beta=beta)\n",
    "\n",
    "print(f\"Base Probability of Default (basePD): {base_pd:.4f}\")\n",
    "print(f\"Odds at Anchor (OddsAtAnchor): {OddsAtAnchor:.4f}\")\n",
    "print(f\"Equation Linear Parameters (eqLinParams): {eqLinParams}\")\n",
    "\n",
    "# Optional: Free up memory\n",
    "del  df_train,df_test\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorecardutils.evaluation_metrics import calculate_breaks,calculate_performance_metrics,gainTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_breaks = calculate_breaks(data=df_all[df_all['dataset']=='train'], \n",
    "                                score='pred_prob',numOfIntervals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_segments = calculate_performance_metrics(\n",
    "    data=df_all,\n",
    "    score_col='pred_prob',\n",
    "    target_col='target',\n",
    "    segments='dataset',\n",
    "    breaks=train_breaks\n",
    ")\n",
    "custom_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_GT= gainTable(data=df_all[df_all['dataset']=='train'],response_name=['Bad','Good'],\n",
    "                    score='pred_prob',ground_truth='target',numOfIntervals=10,\n",
    "                    is_score_prob=True)\n",
    "Train_GT['GainTable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brk=Train_GT['breaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_GT= gainTable(data=df_all[df_all['dataset']=='test'],response_name=['Bad','Good'],\n",
    "                    score='pred_prob',ground_truth='target',numOfIntervals=10,\n",
    "                    is_score_prob=True,breaks=train_brk)\n",
    "Test_GT['GainTable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_GT= gainTable(data=df_all[df_all['dataset']=='train'],response_name=['Bad','Good'],\n",
    "                    score='score',ground_truth='target',numOfIntervals=10,\n",
    "                    is_score_prob=False)\n",
    "Train_GT['GainTable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brk=Train_GT['breaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_GT= gainTable(data=df_all[df_all['dataset']=='test'],response_name=['Bad','Good'],\n",
    "                    score='score',ground_truth='target',numOfIntervals=10,\n",
    "                    is_score_prob=False,breaks=train_brk)\n",
    "Test_GT['GainTable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
