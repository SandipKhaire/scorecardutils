{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load required Liabraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "from scorecardutils.feature_selection import (shap_feature_selection,\n",
    "                                              find_correlation_groups,\n",
    "                                              select_best_features_from_corr_groups,\n",
    "                                              vsi_check)\n",
    "from scorecardutils.BivariatePlot import unified_bivariate_analysis\n",
    "\n",
    "#from feature_engine.selection import SmartCorrelatedSelection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('../data/credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure each feature has correct data types --float,int,catgeory\n",
    "for col in dev_data.select_dtypes(include='object').columns:\n",
    "    dev_data[col] = dev_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define target and features names\n",
    "target = 'default'\n",
    "features = dev_data.drop(columns=[target]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",       # For binary classification\n",
    "    \"eval_metric\": \"auc\",                 # auc\n",
    "    \"learning_rate\": 0.05,                 # Smaller means more trees; safer\n",
    "    \"max_depth\": 6,                       # Controls model complexity\n",
    "    \"subsample\": 0.8,                     # Fraction of samples per tree\n",
    "    \"colsample_bytree\": 0.8,              # Fraction of features per tree\n",
    "    \"lambda\": 1,                          # L2 regularization\n",
    "    \"alpha\": 0,                           # L1 regularization\n",
    "    \"n_estimators\": 100,                  # Total trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,importance_df,_ =shap_feature_selection(train_data=dev_data,feature_names=features,target_name='default',verbose=True,\n",
    "                                                        test_size=0.3,random_state=42,use_train_for_shap=False,\n",
    "                                                        model_params=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,importance_df,shapDF =shap_feature_selection(train_data=dev_data,feature_names=selected_features,target_name='default',verbose=False,\n",
    "                                                        split_data=False,random_state=42,\n",
    "                                                        model_params=xgb_params,create_shap_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups = find_correlation_groups(shapDF, corr_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,selected_features_corr = select_best_features_from_corr_groups(correlated_groups, feature_importance_df=importance_df,\n",
    "                                      feature_importance_col='SHAP_Importance',\n",
    "                                      feature_name_col='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Binning and IV ,Stability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbinning import BinningProcess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndata= pd.read_csv('../data/synthetic_binary_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= syndata.drop(columns=[target])\n",
    "y= syndata[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars= X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract categorical and numerical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "numerical_columns = X_train.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Any Special Codes to treat them in separate bucket\n",
    "e.g \n",
    "special_codes = [-999,-1,-2]\n",
    "or if need to treat separate codes with different values in different special buckets\n",
    "special_codes = {'special_1': -9, \"special_2\": -8, \"special_3\": -7}\n",
    "\"\"\"\n",
    "\n",
    "special_codes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Dictionary with optimal binning fitting options for specific variables. we can update it as per our customization\n",
    "for specific attributes.\n",
    "split_digits: If split_digits is set to 0, the split points are integers otherwise the split points are rounded \n",
    "to the number of digits specified by split_digits.\n",
    "user_splits: If user_splits is set, the splits are fixed to the values specified by user_splits.\n",
    "user_splits_fixed: If user_splits_fixed is set to True, the splits are fixed to the values specified by user_splits.\n",
    "monotonic_trend: If monotonic_trend is set to 'ascending', the bad rate should be non-decreasing.\n",
    "cat_cutoff:Generate bin others with categories in which the fraction of occurrences is below the cat_cutoff value. \n",
    "i.e If cat_cutoff is set to 0.05, the bin will be generated with categories in which the fraction of occurrences is below the cat_cutoff value.\n",
    "\n",
    "Initially can be passed as None. binning_fit_params=None\n",
    "\n",
    "binning_fit_params = {\n",
    "    \"dti\": {\"monotonic_trend\": \"ascending\",\"split_digits\":2 ,\n",
    "            \"user_splits\": [ 8.89, 10.91, 14.68, 16.03,18.23, 20.8 , 22.11, 28.37],\n",
    "           # \"user_splits_fixed\" :[True,True] \n",
    "           }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "binning_fit_params = {\n",
    "\n",
    "    \"loyalty_score\":{\"split_digits\":2,\n",
    "        \"user_splits\": [    -3.07959914, -2.46296906, -1.8946799 , -1.6182403 , -1 ,\n",
    "                            0,  0.37816253,  0.77244589,  1.2557528 ,\n",
    "                            1.77894938],\n",
    "        \"user_splits_fixed\": [False,False,False,False,True,True,False,False,False,False]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By default:optbinning assigns WoE = 0 and event rate = overall mean to special values (like missing or outliers), unless you override it.\n",
    "Update Strategy for Special Values:\n",
    "Strategy A: Neutralize Special Values i.e.Assign WoE = 0 (effectively no contribution to the score).\n",
    "Strategy B: Assign Empirical WoE for Special Values i.e.Let the special valuesâ€™ WoE be calculated based on their actual event rate in the data.This is often used when special codes have meaningful predictive power\n",
    "Strategy C: Merge Special Value into Closest Bin. f a special code behaves like a particular bin (e.g., 999 behaves like bin [30â€“40]), assign its WoE manually to match that binâ€™s WoE\n",
    "\n",
    "binning_transform_params ={\n",
    "   'revol_util':{'metric_special':'empirical'},\n",
    "    'dti':{'metric_special': -0.306345},\n",
    "    'inq_last_6mths':{'metric_special':'empirical'}\n",
    "}\n",
    "\n",
    "or \n",
    "binning_transform_params = None\n",
    "\"\"\"\n",
    "specific_binning_transform_params = {\n",
    "    'age':{'metric_missing':'empirical','metric_special':'empirical'}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define default parameter values\n",
    "default_woe_metric_missing = 0  # or whatever default you prefer\n",
    "default_woe_metric_special = 0  # or whatever default you prefer\n",
    "\n",
    "# Create a complete binning_transform_params dictionary\n",
    "binning_transform_params = {}\n",
    "\n",
    "# For each variable in model_vars\n",
    "for var in model_vars:\n",
    "    if var in specific_binning_transform_params:\n",
    "        # Use the specific parameters if defined\n",
    "        binning_transform_params[var] = specific_binning_transform_params[var]\n",
    "    else:\n",
    "        # Otherwise use default parameters\n",
    "        binning_transform_params[var] = {\n",
    "            'metric_missing': default_woe_metric_missing,\n",
    "            'metric_special': default_woe_metric_missing\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List of variables to be fixed. \n",
    "The binning process will retain these variables if the selection criteria is not satisfied.\n",
    "\"\"\"\n",
    "fixed_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the selection criteria for the binning process\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01, \"max\": 0.5,\"strategy\": \"highest\", \"top\": 50},\n",
    "    \"quality_score\": {\"min\": 0.01}\n",
    "}\n",
    "\n",
    "or \n",
    "selection_criteria = None\n",
    "\"\"\"\n",
    "selection_criteria = {\n",
    "    \"iv\": {\"min\": 0.01}#\"strategy\": \"highest\", \"top\": 11\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_process = BinningProcess(variable_names=model_vars, special_codes=special_codes,\n",
    "                                 categorical_variables=categorical_columns,\n",
    "                                 selection_criteria=selection_criteria,\n",
    "                                 binning_fit_params=binning_fit_params,\n",
    "                                 binning_transform_params=binning_transform_params,\n",
    "                                fixed_variables=fixed_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the binning process    \n",
    "binning_process.fit(X=X_train[model_vars], y=y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save all the variables passed to binning process and their IVs for manual screening\n",
    "iv_tab=binning_process.summary().sort_values(by='iv',ascending=False)\n",
    "#iv_tab.to_excel('iv_tab.xlsx', index=False)\n",
    "iv_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_selected_variables = iv_tab[iv_tab['iv']>0.02]['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To see any specific variable binning table\n",
    "optb = binning_process.get_binned_variable('age')\n",
    "df = optb.binning_table.build()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSI summary\n",
    "csi_summ = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='summary',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")\n",
    "\n",
    "## CSI detailed Summary\n",
    "csi_det = vsi_check(\n",
    "    X_oot=X_test, \n",
    "    X_train=X_train,\n",
    "    binning_process=binning_process,\n",
    "    style='detailed',  # or 'detailed' for bin-level information\n",
    "    psi_min_bin_size=0.01,\n",
    "    max_workers=4  # Adjust based on your CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save csi in excel\n",
    "with pd.ExcelWriter('csi.xlsx', engine='openpyxl', mode='w') as writer:\n",
    "    csi_summ.to_excel(writer, sheet_name='summary', index=False)\n",
    "    csi_det.to_excel(writer, sheet_name='detail', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter stable variables (PSI < threshold)\n",
    "stable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] < 10]['Variable'].tolist()]\n",
    "    \n",
    "# Filter unstable variables (PSI >= threshold)\n",
    "unstable_variables = [str(var) for var in csi_summ[csi_summ['CSI'] >= 10]['Variable'].tolist()]\n",
    "print(\"Unstable Variables:\", unstable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs = [feature for feature in iv_selected_variables if feature not in unstable_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Bivariate plot on both Train/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing training data with a newer time period\n",
    "unified_bivariate_analysis(\n",
    "    binning_process=binning_process,\n",
    "    filename='event_rate_train',\n",
    "    metric='woe',\n",
    "    oot_data= None,  # Data from a more recent time period\n",
    "    target_column=target,\n",
    "    compare_data=False ,\n",
    "    variables=selected_features_ivs,\n",
    "    show_bar_values=True ,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_ivs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transofrm variables to WoE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe = binning_process.transform(X=X_train,metric='woe')\n",
    "X_test_woe = binning_process.transform(X=X_test,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_woe.shape)\n",
    "print(X_test_woe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_woe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of final selected variables\n",
    "final_predictors=list(binning_process.get_support(names=True))\n",
    "#final_predictors = ['loyalty_score','credit_score','customer_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into woe or binned values or event rate\n",
    "X_train_WOE = binning_process.transform(X_train,metric='woe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test example to understand the how binning object trasform the data to woe values\n",
    "test_exmaple = pd.DataFrame([{'age': -999,\n",
    " 'income': -0.8276048978295478,\n",
    " 'experience_years': -0.7913895315832409,\n",
    " 'credit_score': -0.7389923463082454,\n",
    " 'avg_spend': 0.7331633070112105,\n",
    " 'loyalty_score': -0.8702525202009143,\n",
    " 'satisfaction_rating': 2.237864030340072,\n",
    " 'demographic_index': -0.3085181724416579,\n",
    " 'financial_status': -0.0191376466062278,\n",
    " 'work_experience': -1.812865565832083,\n",
    " 'credit_index': 0.5505331954414358,\n",
    " 'customer_group': 'group_B'}])\n",
    "\n",
    "test_WOE = binning_process.transform(test_exmaple,metric='woe')\n",
    "test_WOE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
